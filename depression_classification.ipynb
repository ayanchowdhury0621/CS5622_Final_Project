{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS ONLY ONCE WHEN YOU HAVE NEW DATA\n",
    "\n",
    "# # Function to add the feature descriptions as column names to a DataFrame\n",
    "# def add_feature_descriptions(speaker_df, descriptions_df):\n",
    "#     # Set the new column headers\n",
    "#     descriptions_df.columns = ['feature_name', 'feature_description']\n",
    "#     # Use the 'feature_name' column as the column names for speaker_df\n",
    "#     speaker_df.columns = descriptions_df['feature_name'].values\n",
    "#     return speaker_df\n",
    "\n",
    "\n",
    "# # Function to add the labels to the speaker DataFrame\n",
    "# def add_labels(speaker_df, labels_df, participant_id):\n",
    "#     # Find the matching row in the labels DataFrame by participant ID\n",
    "#     labels_row = labels_df.loc[labels_df['Participant_ID'] == participant_id]\n",
    "#     # If the row is found, add the Depression and Gender values as new columns\n",
    "#     if not labels_row.empty:\n",
    "#         speaker_df['Depression'] = labels_row['Depression'].values[0]\n",
    "#         speaker_df['Gender'] = labels_row['Gender'].values[0]\n",
    "#         speaker_df['Participant_ID'] = participant_id\n",
    "#     return speaker_df\n",
    "\n",
    "# # Paths to CSV files\n",
    "features_description_path = '/Users/Ayan/Desktop/CS5622/HW5/feature_description.csv'\n",
    "labels_path = '/Users/Ayan/Desktop/CS5622/HW5/labels.csv'\n",
    "features_train_dir = '/Users/Ayan/Desktop/CS5622/HW5/features_train'\n",
    "\n",
    "# # Read the feature descriptions and labels CSV files\n",
    "features_description_df = pd.read_csv(features_description_path, encoding='latin-1', header=None)\n",
    "labels_df = pd.read_csv(labels_path, encoding='latin-1')\n",
    "\n",
    "# # Iterate over each speaker CSV file in the features_train directory\n",
    "# for file in os.listdir(features_train_dir):\n",
    "#     if file.endswith('.csv'):\n",
    "#         # Extract the participant ID from the file name\n",
    "#         participant_id = int(file.split('_')[1].split('.')[0])\n",
    "        \n",
    "#         # Read the speaker CSV file\n",
    "#         speaker_df = pd.read_csv(os.path.join(features_train_dir, file), encoding='latin-1')\n",
    "        \n",
    "#         # Add feature descriptions as column headers\n",
    "#         speaker_df = add_feature_descriptions(speaker_df, features_description_df)\n",
    "        \n",
    "#         # Add labels based on participant ID\n",
    "#         speaker_df = add_labels(speaker_df, labels_df, participant_id)\n",
    "                \n",
    "#         # make sure the dataframe is updated and the file itself is updated too\n",
    "#         speaker_df.to_csv(os.path.join(features_train_dir, file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to aggregate all training csv's into one big training data table\n",
    "def aggregate_training_data(features_train_dir):\n",
    "    # Create an empty DataFrame to store the aggregated data\n",
    "    aggregated_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each speaker CSV file in the features_train directory\n",
    "    for file in os.listdir(features_train_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            # Read the speaker CSV file\n",
    "            speaker_df = pd.read_csv(os.path.join(features_train_dir, file), encoding='latin-1')\n",
    "            # Append the speaker data to the aggregated DataFrame\n",
    "            aggregated_df = pd.concat([aggregated_df, speaker_df], ignore_index=True)\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "# Aggregate all training data into one DataFrame\n",
    "training_data = aggregate_training_data(features_train_dir)\n",
    "\n",
    "# Save the aggregated training data to a CSV file\n",
    "training_data.to_csv('/Users/Ayan/Desktop/CS5622/HW5/training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN For Depression Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the training data\n",
    "training_data = pd.read_csv('/Users/Ayan/Desktop/CS5622/HW5/training_data.csv', encoding='latin-1')\n",
    "\n",
    "# print the first 5 rows of the training data\n",
    "print(training_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
