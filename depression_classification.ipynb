{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## RUN THIS ONLY ONCE WHEN YOU HAVE NEW DATA\n",
    "\n",
    "# # Function to add the feature descriptions as column names to a DataFrame\n",
    "# def add_feature_descriptions(speaker_df, descriptions_df):\n",
    "#     # Set the new column headers\n",
    "#     descriptions_df.columns = ['feature_name', 'feature_description']\n",
    "#     # Use the 'feature_name' column as the column names for speaker_df\n",
    "#     speaker_df.columns = descriptions_df['feature_name'].values\n",
    "#     return speaker_df\n",
    "\n",
    "\n",
    "# # Function to add the labels to the speaker DataFrame\n",
    "# def add_labels(speaker_df, labels_df, participant_id):\n",
    "#     # Find the matching row in the labels DataFrame by participant ID\n",
    "#     labels_row = labels_df.loc[labels_df['Participant_ID'] == participant_id]\n",
    "#     # If the row is found, add the Depression and Gender values as new columns\n",
    "#     if not labels_row.empty:\n",
    "#         speaker_df['Depression'] = labels_row['Depression'].values[0]\n",
    "#         speaker_df['Gender'] = labels_row['Gender'].values[0]\n",
    "#         speaker_df['Participant_ID'] = participant_id\n",
    "#     return speaker_df\n",
    "\n",
    "# # # Paths to CSV files\n",
    "# features_description_path = '/Users/Ayan/Desktop/CS5622/HW5/feature_description.csv'\n",
    "# labels_path = '/Users/Ayan/Desktop/CS5622/HW5/labels.csv'\n",
    "# features_train_dir = '/Users/Ayan/Desktop/CS5622/HW5/features_train'\n",
    "# features_test_dir = '/Users/Ayan/Desktop/CS5622/HW5/features_test'\n",
    "\n",
    "\n",
    "# # # Read the feature descriptions and labels CSV files\n",
    "# features_description_df = pd.read_csv(features_description_path, encoding='latin-1', header=None)\n",
    "# labels_df = pd.read_csv(labels_path, encoding='latin-1')\n",
    "\n",
    "# # Iterate over each speaker CSV file in the features_train directory\n",
    "# for file in os.listdir(features_test_dir):\n",
    "#     if file.endswith('.csv'):\n",
    "#         # Extract the participant ID from the file name\n",
    "#         participant_id = int(file.split('_')[1].split('.')[0])\n",
    "#         # Read the speaker CSV file\n",
    "#         speaker_df = pd.read_csv(os.path.join(features_test_dir, file), encoding='latin-1')\n",
    "        \n",
    "#         # Add feature descriptions as column headers\n",
    "#         speaker_df = add_feature_descriptions(speaker_df, features_description_df)\n",
    "        \n",
    "#         # Add labels based on participant ID\n",
    "#         speaker_df = add_labels(speaker_df, labels_df, participant_id)\n",
    "        \n",
    "#          # make sure the dataframe is updated and the file itself is updated too\n",
    "#         speaker_df.to_csv(os.path.join(features_test_dir, file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to aggregate all training csv's into one big training data table\n",
    "def aggregate_training_data(features_train_dir):\n",
    "    # Create an empty DataFrame to store the aggregated data\n",
    "    aggregated_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each speaker CSV file in the features_train directory\n",
    "    for file in os.listdir(features_train_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            # Read the speaker CSV file\n",
    "            speaker_df = pd.read_csv(os.path.join(features_train_dir, file), encoding='latin-1')\n",
    "            # Append the speaker data to the aggregated DataFrame\n",
    "            aggregated_df = pd.concat([aggregated_df, speaker_df], ignore_index=True)\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "# Aggregate all training data into one DataFrame\n",
    "training_data = aggregate_training_data(features_train_dir)\n",
    "testing_data = aggregate_training_data(features_test_dir)\n",
    "\n",
    "# Save the aggregated training data to a CSV file\n",
    "training_data.to_csv('/Users/Ayan/Desktop/CS5622/HW5/training_data.csv', index=False)\n",
    "testing_data.to_csv('/Users/Ayan/Desktop/CS5622/HW5/testing_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN For Depression Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_amean</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_stddevNorm</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_percentile20.0</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_percentile50.0</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_percentile80.0</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>loudnessPeaksPerSec</th>\n",
       "      <th>VoicedSegmentsPerSec</th>\n",
       "      <th>MeanVoicedSegmentLengthSec</th>\n",
       "      <th>StddevVoicedSegmentLengthSec</th>\n",
       "      <th>MeanUnvoicedSegmentLength</th>\n",
       "      <th>StddevUnvoicedSegmentLength</th>\n",
       "      <th>equivalentSoundLevel_dBp</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Participant_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.442284</td>\n",
       "      <td>0.015231</td>\n",
       "      <td>23.083265</td>\n",
       "      <td>23.519197</td>\n",
       "      <td>23.799660</td>\n",
       "      <td>0.716394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.109734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.703704</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-47.326970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.658195</td>\n",
       "      <td>0.095594</td>\n",
       "      <td>24.275490</td>\n",
       "      <td>27.404346</td>\n",
       "      <td>29.017082</td>\n",
       "      <td>4.741592</td>\n",
       "      <td>61.829530</td>\n",
       "      <td>67.673560</td>\n",
       "      <td>20.461290</td>\n",
       "      <td>11.705440</td>\n",
       "      <td>...</td>\n",
       "      <td>3.131991</td>\n",
       "      <td>2.036199</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.235472</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.087321</td>\n",
       "      <td>-41.121784</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.265000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.614662</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>34.433628</td>\n",
       "      <td>34.559757</td>\n",
       "      <td>34.764160</td>\n",
       "      <td>0.330532</td>\n",
       "      <td>8.279264</td>\n",
       "      <td>5.828207</td>\n",
       "      <td>8.208370</td>\n",
       "      <td>6.596444</td>\n",
       "      <td>...</td>\n",
       "      <td>5.084746</td>\n",
       "      <td>1.886793</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-33.531155</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.782654</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>43.540440</td>\n",
       "      <td>43.602890</td>\n",
       "      <td>44.168890</td>\n",
       "      <td>0.628452</td>\n",
       "      <td>7.757357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.900528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531646</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-39.635094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F0semitoneFrom27.5Hz_sma3nz_amean  F0semitoneFrom27.5Hz_sma3nz_stddevNorm  \\\n",
       "0                          23.442284                                0.015231   \n",
       "1                          26.658195                                0.095594   \n",
       "2                           0.000000                                0.000000   \n",
       "3                          34.614662                                0.005980   \n",
       "4                          43.782654                                0.006530   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_percentile20.0  \\\n",
       "0                                   23.083265   \n",
       "1                                   24.275490   \n",
       "2                                    0.000000   \n",
       "3                                   34.433628   \n",
       "4                                   43.540440   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_percentile50.0  \\\n",
       "0                                   23.519197   \n",
       "1                                   27.404346   \n",
       "2                                    0.000000   \n",
       "3                                   34.559757   \n",
       "4                                   43.602890   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_percentile80.0  \\\n",
       "0                                   23.799660   \n",
       "1                                   29.017082   \n",
       "2                                    0.000000   \n",
       "3                                   34.764160   \n",
       "4                                   44.168890   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2  \\\n",
       "0                                  0.716394   \n",
       "1                                  4.741592   \n",
       "2                                  0.000000   \n",
       "3                                  0.330532   \n",
       "4                                  0.628452   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope  \\\n",
       "0                                     0.000000   \n",
       "1                                    61.829530   \n",
       "2                                     0.000000   \n",
       "3                                     8.279264   \n",
       "4                                     7.757357   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope  \\\n",
       "0                                       0.000000   \n",
       "1                                      67.673560   \n",
       "2                                       0.000000   \n",
       "3                                       5.828207   \n",
       "4                                       0.000000   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope  \\\n",
       "0                                     -0.109734   \n",
       "1                                     20.461290   \n",
       "2                                      0.000000   \n",
       "3                                      8.208370   \n",
       "4                                      3.900528   \n",
       "\n",
       "   F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope  ...  loudnessPeaksPerSec  \\\n",
       "0                                        0.000000  ...             3.703704   \n",
       "1                                       11.705440  ...             3.131991   \n",
       "2                                        0.000000  ...             3.333334   \n",
       "3                                        6.596444  ...             5.084746   \n",
       "4                                        0.000000  ...             2.531646   \n",
       "\n",
       "   VoicedSegmentsPerSec  MeanVoicedSegmentLengthSec  \\\n",
       "0              2.040816                    0.080000   \n",
       "1              2.036199                    0.344444   \n",
       "2              0.000000                    0.000000   \n",
       "3              1.886793                    0.420000   \n",
       "4              1.351351                    0.110000   \n",
       "\n",
       "   StddevVoicedSegmentLengthSec  MeanUnvoicedSegmentLength  \\\n",
       "0                      0.000000                      0.380   \n",
       "1                      0.235472                      0.115   \n",
       "2                      0.000000                      0.240   \n",
       "3                      0.000000                      0.040   \n",
       "4                      0.000000                      0.300   \n",
       "\n",
       "   StddevUnvoicedSegmentLength  equivalentSoundLevel_dBp  Depression  Gender  \\\n",
       "0                     0.000000                -47.326970           1       1   \n",
       "1                     0.087321                -41.121784           1       1   \n",
       "2                     0.000000                -56.265000           1       1   \n",
       "3                     0.020000                -33.531155           1       1   \n",
       "4                     0.010000                -39.635094           1       1   \n",
       "\n",
       "   Participant_ID  \n",
       "0             448  \n",
       "1             448  \n",
       "2             448  \n",
       "3             448  \n",
       "4             448  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the training data\n",
    "training_data = pd.read_csv('/Users/Ayan/Desktop/CS5622/HW5/training_data.csv', encoding='latin-1')\n",
    "\n",
    "# print the first 5 rows of the training data\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "def interpolate(train):\n",
    "    for column in train.columns:\n",
    "        # If the column is not 'Depression', 'Gender', 'participant_id'\n",
    "        if column not in ['Depression', 'Gender', 'Participant_ID']:\n",
    "            train[column] = train[column].replace(0, np.nan)\n",
    "            train[column] = train[column].interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "    return train\n",
    "\n",
    "# find rows with outliers and remove them\n",
    "# def remove_outliers(train):\n",
    "#     # Calculate the z-scores of each feature in the training data\n",
    "#     z_scores = (train.drop(columns=['Depression', 'Gender', 'Participant_ID']).apply(lambda x: np.abs((x - x.mean()) / x.std())))\n",
    "#     # Find the rows with z-scores greater than 3\n",
    "#     outliers = z_scores[(z_scores > 4).any(axis=1)]\n",
    "#     # Remove the rows with outliers\n",
    "#     train = train.drop(outliers.index)\n",
    "#     return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# interpolate the training data\n",
    "training_data = interpolate(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# remove first row of the training data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m y_train \u001b[38;5;241m=\u001b[39m training_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepression\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n\u001b[1;32m      7\u001b[0m X_test \u001b[38;5;241m=\u001b[39m testing_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepression\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParticipant_ID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "X_train = training_data.drop(columns=['Depression', 'Gender', 'Participant_ID']) \n",
    "X_train = X_train.to_numpy()\n",
    "# remove first row of the training data\n",
    "y_train = training_data['Depression']\n",
    "\n",
    "X_train.head()\n",
    "X_test = testing_data.drop(columns=['Depression', 'Gender', 'Participant_ID'])\n",
    "X_test = X_test.to_numpy()\n",
    "# # remove first row of the testing data\n",
    "# X_test = X_test.iloc[1:]\n",
    "# y_test = testing_data['Depression']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13539, 88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ayan/Desktop/CS5622/HW5/myenv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6983 - loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7123 - loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7080 - loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7134 - loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7071 - loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7123 - loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7127 - loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7124 - loss: nan\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3260, 3259]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (model\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CS5622/HW5/myenv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/CS5622/HW5/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/CS5622/HW5/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CS5622/HW5/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3260, 3259]"
     ]
    }
   ],
   "source": [
    "# Assuming `X_train` and `X_test` are numpy arrays after proper preprocessing\n",
    "# max_length should be the number of time steps in each sequence\n",
    "# X_train.shape[1] should give you the number of features\n",
    "\n",
    "print(X_train.shape)  # To check the shape of your input data\n",
    "max_length = X_train.shape[1]  # This is the number of features in your dataset\n",
    "\n",
    "# Define RNN architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(None, max_length)))  # The 'None' here allows variable sequence length\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Since LSTM expects a 3D input of shape [samples, time steps, features]\n",
    "# And each row in your data corresponds to one time step with multiple features\n",
    "# You should reshape your data to add the time step dimension if not already done\n",
    "# For example:\n",
    "X_train = np.expand_dims(X_train, axis=1)  # This adds the time step dimension\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
